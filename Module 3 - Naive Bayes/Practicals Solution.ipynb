{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# DOST AI Summer School 2017\n",
    "# Multinomial Naive Bayes Spam Classifier\n",
    "\n",
    "Prepared by Jerelyn Co (ADMU) and Hadrian Paulo Lim (ADMU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Practicals: Spam Filtering with Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "2. Representing text as numerical data\n",
    "3. Reading a text-based dataset into pandas\n",
    "4. Vectorizing our dataset\n",
    "5. Building and evaluating a model\n",
    "6. Comparing models\n",
    "7. Examining a model for further insight\n",
    "9. Tuning the vectorizer (challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 1: Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model training\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cab', 'call', 'me', 'please', 'tonight', 'you']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the type of the document-term matrix\n",
    "type(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# examine the sparse matrix contents\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "In order to **make a prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 3: Reading a text-based dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read file into pandas using a relative path\n",
    "path = 'data/spam_ham.csv'\n",
    "spam_ham = pd.read_csv(path, header=0, names=['label', 'location','message'])\n",
    "spam_ham.drop('location', axis=1, inplace=True)\n",
    "spam_ham.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30974, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "spam_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...\n",
       "1  spam  Academic Qualifications available from prestig...\n",
       "2   ham  Greetings all. This is to verify your subscrip...\n",
       "3  spam  try chauncey may conferred the luscious not co...\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...\n",
       "5   ham  It's working here. I have departed almost tota...\n",
       "6  spam  The OIL sector is going crazy. This is our wee...\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    19280\n",
       "ham     11694\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "spam_ham.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "spam_ham['label_num'] = spam_ham.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic Qualifications available from prestig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is to verify your subscrip...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>try chauncey may conferred the luscious not co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's quiet. Too quiet. Well, how about a straw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>It's working here. I have departed almost tota...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spam</td>\n",
       "      <td>The OIL sector is going crazy. This is our wee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Little magic. Perfect weekends.http://othxu.rz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Greetings all. This is a mass acknowledgement ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi, L C P A X V V e I r m a A I v A o b n L A ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0  spam  LUXURY WATCHES - BUY YOUR OWN ROLEX FOR ONLY $...          1\n",
       "1  spam  Academic Qualifications available from prestig...          1\n",
       "2   ham  Greetings all. This is to verify your subscrip...          0\n",
       "3  spam  try chauncey may conferred the luscious not co...          1\n",
       "4   ham  It's quiet. Too quiet. Well, how about a straw...          0\n",
       "5   ham  It's working here. I have departed almost tota...          0\n",
       "6  spam  The OIL sector is going crazy. This is our wee...          1\n",
       "7  spam  Little magic. Perfect weekends.http://othxu.rz...          1\n",
       "8   ham  Greetings all. This is a mass acknowledgement ...          0\n",
       "9  spam  Hi, L C P A X V V e I r m a A I v A o b n L A ...          1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "spam_ham.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30974,)\n",
      "(30974,)\n"
     ]
    }
   ],
   "source": [
    "# how to define X and y (from the SMS data) for use with COUNTVECTORIZER\n",
    "X = spam_ham.message\n",
    "y = spam_ham.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23230,)\n",
      "(7744,)\n",
      "(23230,)\n",
      "(7744,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 4: Vectorizing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '000000',\n",
       " '0000000',\n",
       " '00000000',\n",
       " '000000000',\n",
       " '00000000000000',\n",
       " '000000000000000000000000000000049999999999999e9',\n",
       " '0000000000000000000000000000000500000000000000e9',\n",
       " '0000000000000016666l',\n",
       " '0000000000000017d',\n",
       " '00000000000000e',\n",
       " '0000000000status',\n",
       " '0000000001d0',\n",
       " '0000000001l0',\n",
       " '0000000010000000004l0',\n",
       " '0000000016',\n",
       " '000000001d0',\n",
       " '00000000message',\n",
       " '00000000x',\n",
       " '00000001',\n",
       " '00000001irdecode',\n",
       " '00000004',\n",
       " '00000010',\n",
       " '00000010pwm',\n",
       " '00000011',\n",
       " '0000001196',\n",
       " '00000049',\n",
       " '0000005',\n",
       " '000000eb',\n",
       " '000001',\n",
       " '00000100',\n",
       " '00000100shaftencoder',\n",
       " '000001bdaaa0',\n",
       " '000001bdc5a5',\n",
       " '000001bdcaf3',\n",
       " '000001bdd411',\n",
       " '000001bdd98c',\n",
       " '000001bdda70',\n",
       " '000001bde0a0',\n",
       " '000001bed6b7',\n",
       " '000001c64310',\n",
       " '000001c64562',\n",
       " '000001c64585',\n",
       " '000001c64615',\n",
       " '000001c6465f',\n",
       " '000001c6468e',\n",
       " '000001c676b8',\n",
       " '0000020',\n",
       " '0000040',\n",
       " '0000040b',\n",
       " '0000040c',\n",
       " '000005',\n",
       " '0000060',\n",
       " '00001',\n",
       " '000010',\n",
       " '0000100',\n",
       " '00001000',\n",
       " '00001004',\n",
       " '00001008',\n",
       " '0000100c',\n",
       " '00001010',\n",
       " '00001014',\n",
       " '00001018',\n",
       " '0000101c',\n",
       " '00001023',\n",
       " '00001026',\n",
       " '00001028',\n",
       " '0000102c',\n",
       " '00001030',\n",
       " '00001034',\n",
       " '00001038',\n",
       " '0000103e',\n",
       " '00001040',\n",
       " '00001044',\n",
       " '00001048',\n",
       " '0000104c',\n",
       " '00001050',\n",
       " '00001054',\n",
       " '0000105a',\n",
       " '0000105ci',\n",
       " '0000120',\n",
       " '0000140',\n",
       " '0000160',\n",
       " '00001808',\n",
       " '0000180cmain',\n",
       " '0000200',\n",
       " '0000220',\n",
       " '0000240',\n",
       " '0000260',\n",
       " '0000300',\n",
       " '00003001722',\n",
       " '000031',\n",
       " '0000320',\n",
       " '000033',\n",
       " '0000340',\n",
       " '0000360',\n",
       " '00004',\n",
       " '0000400',\n",
       " '0000420',\n",
       " '0000440',\n",
       " '000046',\n",
       " '0000460',\n",
       " '0000500',\n",
       " '0000504',\n",
       " '000061',\n",
       " '000066',\n",
       " '000076',\n",
       " '000092',\n",
       " '00009800',\n",
       " '00009804',\n",
       " '0000bd',\n",
       " '0000bi',\n",
       " '0000bytes',\n",
       " '0000comment',\n",
       " '0000content',\n",
       " '0000d5',\n",
       " '0000date',\n",
       " '0000delivered',\n",
       " '0000ff',\n",
       " '0000from',\n",
       " '0000importance',\n",
       " '0000in',\n",
       " '0000instituteof0000',\n",
       " '0000message',\n",
       " '0000mime',\n",
       " '0000nline',\n",
       " '0000nology',\n",
       " '0000nology404',\n",
       " '0000of',\n",
       " '0000our',\n",
       " '0000received',\n",
       " '0000reply',\n",
       " '0000to',\n",
       " '0000x',\n",
       " '0001',\n",
       " '00010000',\n",
       " '00010000spdseta',\n",
       " '000101376290',\n",
       " '000101bdc5a5',\n",
       " '000101bdcbb7',\n",
       " '000101bed6b7',\n",
       " '000101bedba4',\n",
       " '00010246',\n",
       " '00010246ebx',\n",
       " '000107',\n",
       " '00011',\n",
       " '00014',\n",
       " '0001_mayprod',\n",
       " '0001pt',\n",
       " '0001we',\n",
       " '0001x',\n",
       " '0002',\n",
       " '000201bdc8cb',\n",
       " '000201bdcbb8',\n",
       " '000201c265a3',\n",
       " '00024355',\n",
       " '000255000',\n",
       " '0002phone',\n",
       " '0003',\n",
       " '000301bde673',\n",
       " '000301c634d3',\n",
       " '000301c6430e',\n",
       " '00033577',\n",
       " '0003gy',\n",
       " '0003qj',\n",
       " '0003zh',\n",
       " '0004',\n",
       " '000401bdd670',\n",
       " '000401bde673',\n",
       " '000420',\n",
       " '00048z',\n",
       " '0004ek',\n",
       " '0004ti',\n",
       " '0005',\n",
       " '000501bdca45',\n",
       " '000501bdd670',\n",
       " '000501bed6db',\n",
       " '000501c62cfa',\n",
       " '000548',\n",
       " '0005859375',\n",
       " '0005iw',\n",
       " '0006',\n",
       " '000601bdd38d',\n",
       " '000601bed721',\n",
       " '0006eu',\n",
       " '0006pn',\n",
       " '0006sc',\n",
       " '0006z8',\n",
       " '0007',\n",
       " '0007051519140',\n",
       " '00077u',\n",
       " '0007ka',\n",
       " '0007mt',\n",
       " '0008',\n",
       " '000801c59181',\n",
       " '0009',\n",
       " '0009lcdrout',\n",
       " '000a',\n",
       " '000a01bde6a3',\n",
       " '000a01bdea63',\n",
       " '000abpz20',\n",
       " '000antiprotons',\n",
       " '000audre',\n",
       " '000b01c66cb8',\n",
       " '000bachelor',\n",
       " '000barrels',\n",
       " '000br',\n",
       " '000c',\n",
       " '000c01bdcdc7',\n",
       " '000c01c6714b',\n",
       " '000copies',\n",
       " '000d01c0dff7',\n",
       " '000dear',\n",
       " '000doctorate',\n",
       " '000e',\n",
       " '000e01bee437',\n",
       " '000e137038fe07f0ea1e00000e1370ad14f0a238060170380382783800fc7f18157f941b',\n",
       " '000equals',\n",
       " '000eur',\n",
       " '000f01bee9ca',\n",
       " '000hours',\n",
       " '000i',\n",
       " '000industry',\n",
       " '000job',\n",
       " '000k',\n",
       " '000km',\n",
       " '000live',\n",
       " '000m',\n",
       " '000master',\n",
       " '000miles',\n",
       " '000mk',\n",
       " '000no',\n",
       " '000or',\n",
       " '000over',\n",
       " '000person',\n",
       " '000rpm',\n",
       " '000some',\n",
       " '000stipend',\n",
       " '000students',\n",
       " '000summary',\n",
       " '000t',\n",
       " '000this',\n",
       " '000uponcompletion',\n",
       " '000visitors',\n",
       " '000yes',\n",
       " '000you',\n",
       " '000контактные',\n",
       " '000アブノーマル1時間',\n",
       " '000元',\n",
       " '000元以內',\n",
       " '000円',\n",
       " '000円のみが必要となりますが',\n",
       " '000円不要',\n",
       " '000性感ノーマル',\n",
       " '001',\n",
       " '0010',\n",
       " '00100000',\n",
       " '00100000spdsetb',\n",
       " '001001bedde0',\n",
       " '001001bee9ca',\n",
       " '00101380381e0700ea1fff5b13f8ea17e00010c7fca6ea11f8ea120cea1c07381803801210380001c0a214e0a4127012f0a200e013c01280ea4003148038200700ea1006ea0c1cea03f013227ea018',\n",
       " '0011',\n",
       " '001101bdd428',\n",
       " '001111111',\n",
       " '0012',\n",
       " '001201bee9d7',\n",
       " '001201beedd8',\n",
       " '00126',\n",
       " '0013',\n",
       " '0014',\n",
       " '001401bf04c9',\n",
       " '0015',\n",
       " '001501bde71a',\n",
       " '001532edt',\n",
       " '0016',\n",
       " '001601bdd428',\n",
       " '001601bde7b0',\n",
       " '0017',\n",
       " '001701bdd73e',\n",
       " '001701bde82b',\n",
       " '001701bed5b2',\n",
       " '0018',\n",
       " '001801bde88a',\n",
       " '001801beda0f',\n",
       " '001888',\n",
       " '0019',\n",
       " '001a',\n",
       " '001aa',\n",
       " '001c',\n",
       " '001d',\n",
       " '001e133000231370ea438014e01283ea8700a2380701c0120ea3381c0380a4eb0700a35bea0c3eea03ceea000ea25b1260eaf0381330485aea80c0ea4380003ec7fc141f7b9418',\n",
       " '001e1360002313e0ea4380eb81c01283ea8701a238070380120ea3381c0700a31408eb0e101218121ceb1e20ea0c263807c3c015157b941a',\n",
       " '001eb1ec',\n",
       " '001eboard',\n",
       " '001eeb60e00023ebe0f0384380e1eb81c000831470d887011330a23907038020120ea3391c070040a31580a2ec0100130f380c0b02380613843803e0f81c157b9420',\n",
       " '001f01bdd431',\n",
       " '001f01c275ca',\n",
       " '001fb512f8391e03c03800181418123038200780a200401410a2eb0f001280a200001400131ea45ba45ba45ba4485aa41203b5fc1d2277a123',\n",
       " '001fboard',\n",
       " '001fd',\n",
       " '001hetg',\n",
       " '001http',\n",
       " '001kp',\n",
       " '001mk',\n",
       " '002',\n",
       " '0020',\n",
       " '002001bdd439',\n",
       " '00203228888',\n",
       " '0020afec18ca',\n",
       " '0020j',\n",
       " '0021',\n",
       " '002101bdd459',\n",
       " '0022',\n",
       " '002201bdd548',\n",
       " '002249',\n",
       " '00228',\n",
       " '002289481249mail',\n",
       " '0022uf',\n",
       " '0023',\n",
       " '002301bdd548',\n",
       " '002301c0faae',\n",
       " '002301c23827',\n",
       " '002321',\n",
       " '00233',\n",
       " '0024',\n",
       " '002401bdd548',\n",
       " '0025',\n",
       " '0025fax',\n",
       " '0026',\n",
       " '002601c66a38',\n",
       " '0027',\n",
       " '002712est',\n",
       " '0028',\n",
       " '002801c13bab',\n",
       " '0028ii',\n",
       " '0029',\n",
       " '002930_voxinfo',\n",
       " '0029817706609725333l434294481',\n",
       " '002983',\n",
       " '0029porta',\n",
       " '002_dragon004200943940content',\n",
       " '002_dragon008535651103',\n",
       " '002_dragon013699393919',\n",
       " '002_dragon019357534987content',\n",
       " '002_dragon020181421106',\n",
       " '002_dragon032685489904content',\n",
       " '002_dragon034150072259',\n",
       " '002_dragon034633567807content',\n",
       " '002_dragon039925383399content',\n",
       " '002_dragon040476364422',\n",
       " '002_dragon048889247829content',\n",
       " '002_dragon056675156800',\n",
       " '002_dragon058285243905content',\n",
       " '002_dragon060280103893content',\n",
       " '002_dragon073148149514',\n",
       " '002_dragon074457059520',\n",
       " '002_dragon077329414837',\n",
       " '002_dragon080566096389content',\n",
       " '002_dragon092734619076content',\n",
       " '002_dragon100455099132content',\n",
       " '002_dragon108076263577content',\n",
       " '002_dragon108468622097content',\n",
       " '002_dragon120569444328',\n",
       " '002_dragon122521392039content',\n",
       " '002_dragon128631707502content',\n",
       " '002_dragon133773915096content',\n",
       " '002_dragon136224228356content',\n",
       " '002_dragon138839954923',\n",
       " '002_dragon140844353194',\n",
       " '002_dragon142360745850content',\n",
       " '002_dragon143330654218',\n",
       " '002_dragon149449844292',\n",
       " '002_dragon161509917710',\n",
       " '002_dragon162756092795content',\n",
       " '002_dragon168204929497content',\n",
       " '002_dragon169002695074',\n",
       " '002_dragon169085030403content',\n",
       " '002_dragon176086318908',\n",
       " '002_dragon177944757813content',\n",
       " '002_dragon179326334746',\n",
       " '002_dragon183888777798content',\n",
       " '002_dragon183941553104content',\n",
       " '002_dragon185781585974',\n",
       " '002_dragon188257448684content',\n",
       " '002_dragon188333289331content',\n",
       " '002_dragon189316002559content',\n",
       " '002_dragon193530954717content',\n",
       " '002_dragon196072547742',\n",
       " '002_dragon198189501342content',\n",
       " '002_dragon203013389770content',\n",
       " '002_dragon204052897310',\n",
       " '002_dragon205793002835content',\n",
       " '002_dragon206018273441content',\n",
       " '002_dragon207785784570content',\n",
       " '002_dragon210159025107content',\n",
       " '002_dragon211481662238',\n",
       " '002_dragon212983034666content',\n",
       " '002_dragon213924637584content',\n",
       " '002_dragon214166912429',\n",
       " '002_dragon214895540320',\n",
       " '002_dragon215886918037',\n",
       " '002_dragon216410465126content',\n",
       " '002_dragon231888896784content',\n",
       " '002_dragon233134712957content',\n",
       " '002_dragon234879898522content',\n",
       " '002_dragon235764159952content',\n",
       " '002_dragon237516939735',\n",
       " '002_dragon239516577637content',\n",
       " '002_dragon240032945636content',\n",
       " '002_dragon248564804421content',\n",
       " '002_dragon249354945590content',\n",
       " '002_dragon249807569787content',\n",
       " '002_dragon254481303756',\n",
       " '002_dragon256918362398',\n",
       " '002_dragon262221859113',\n",
       " '002_dragon264396653478',\n",
       " '002_dragon264441716722content',\n",
       " '002_dragon265325440711content',\n",
       " '002_dragon266209308694content',\n",
       " '002_dragon269013230617content',\n",
       " '002_dragon270367826058content',\n",
       " '002_dragon273382864054content',\n",
       " '002_dragon273895548293',\n",
       " '002_dragon281660342386content',\n",
       " '002_dragon285173245356content',\n",
       " '002_dragon289924567963content',\n",
       " '002_dragon291265061908content',\n",
       " '002_dragon292505557095content',\n",
       " '002_dragon293119990835content',\n",
       " '002_dragon295843020376content',\n",
       " '002_dragon302510766348',\n",
       " '002_dragon302921738635',\n",
       " '002_dragon310127751282content',\n",
       " '002_dragon310651914794content',\n",
       " '002_dragon313149702908',\n",
       " '002_dragon317695925892content',\n",
       " '002_dragon318665289543content',\n",
       " '002_dragon319948883600',\n",
       " '002_dragon320946592690content',\n",
       " '002_dragon322915006407',\n",
       " '002_dragon324589698709content',\n",
       " '002_dragon327437312378content',\n",
       " '002_dragon327643673166content',\n",
       " '002_dragon330573254373content',\n",
       " '002_dragon333436883450content',\n",
       " '002_dragon336214030309content',\n",
       " '002_dragon340834821974',\n",
       " '002_dragon341612040241',\n",
       " '002_dragon343333554216',\n",
       " '002_dragon345724565924content',\n",
       " '002_dragon346394276285content',\n",
       " '002_dragon348016147037content',\n",
       " '002_dragon356616615600content',\n",
       " '002_dragon359805902139content',\n",
       " '002_dragon361767389765',\n",
       " '002_dragon366284922033',\n",
       " '002_dragon370830372714',\n",
       " '002_dragon377070002978content',\n",
       " '002_dragon377441852287',\n",
       " '002_dragon384660614980content',\n",
       " '002_dragon389780210192content',\n",
       " '002_dragon390632298472content',\n",
       " '002_dragon391848222368content',\n",
       " '002_dragon399477789492content',\n",
       " '002_dragon402079065150',\n",
       " '002_dragon402740244099content',\n",
       " '002_dragon409823729458content',\n",
       " '002_dragon410509063251content',\n",
       " '002_dragon411110209560content',\n",
       " '002_dragon413436947052content',\n",
       " '002_dragon415805250710content',\n",
       " '002_dragon416123410162content',\n",
       " '002_dragon425323668785content',\n",
       " '002_dragon431429810021content',\n",
       " '002_dragon431676018905content',\n",
       " '002_dragon432852498332content',\n",
       " '002_dragon435496836113',\n",
       " '002_dragon437917652885content',\n",
       " '002_dragon440034119332',\n",
       " '002_dragon442592498835',\n",
       " '002_dragon443472164152content',\n",
       " '002_dragon443689150123content',\n",
       " '002_dragon444004361912content',\n",
       " '002_dragon448288168555content',\n",
       " '002_dragon451319953791',\n",
       " '002_dragon451657700235content',\n",
       " '002_dragon456176210945content',\n",
       " '002_dragon468266803279content',\n",
       " '002_dragon470466639645',\n",
       " '002_dragon473323566965',\n",
       " '002_dragon476540816282content',\n",
       " '002_dragon477399743496content',\n",
       " '002_dragon479331544790content',\n",
       " '002_dragon483579780476content',\n",
       " '002_dragon484358097899content',\n",
       " '002_dragon488902243432',\n",
       " '002_dragon491393046235',\n",
       " '002_dragon495877656850content',\n",
       " '002_dragon503725778714_',\n",
       " '002_dragon504217449345',\n",
       " '002_dragon505110412875',\n",
       " '002_dragon505932322972',\n",
       " '002_dragon506805364816content',\n",
       " '002_dragon508712711421content',\n",
       " '002_dragon512122577234',\n",
       " '002_dragon513692340014content',\n",
       " '002_dragon514676478309content',\n",
       " '002_dragon515128794190',\n",
       " '002_dragon516011979524content',\n",
       " '002_dragon516666948361content',\n",
       " '002_dragon518255923908content',\n",
       " '002_dragon519557785805',\n",
       " '002_dragon520683972230content',\n",
       " '002_dragon522040799568',\n",
       " '002_dragon527791339896content',\n",
       " '002_dragon530821623860content',\n",
       " '002_dragon533835082890content',\n",
       " '002_dragon535670459181content',\n",
       " '002_dragon536989065088content',\n",
       " '002_dragon538638107395content',\n",
       " '002_dragon540629808243content',\n",
       " '002_dragon542105054566content',\n",
       " '002_dragon542522505882content',\n",
       " '002_dragon544018013072content',\n",
       " '002_dragon546536074428content',\n",
       " '002_dragon547081415263content',\n",
       " '002_dragon547831489158',\n",
       " '002_dragon554816776882content',\n",
       " '002_dragon557516700063content',\n",
       " '002_dragon558995758314',\n",
       " '002_dragon560194215614content',\n",
       " '002_dragon561824435930content',\n",
       " '002_dragon563227845761',\n",
       " '002_dragon564322207242content',\n",
       " '002_dragon571434638457',\n",
       " '002_dragon574371893608content',\n",
       " '002_dragon575585758776content',\n",
       " '002_dragon577596397905content',\n",
       " '002_dragon583411697069content',\n",
       " '002_dragon584915480615',\n",
       " '002_dragon585001720044content',\n",
       " '002_dragon585387820253',\n",
       " '002_dragon586232798130content',\n",
       " '002_dragon591660557037content',\n",
       " '002_dragon596828381337content',\n",
       " '002_dragon597439856990',\n",
       " '002_dragon599296306728',\n",
       " '002_dragon607166703191_',\n",
       " '002_dragon610136592431content',\n",
       " '002_dragon610953810273content',\n",
       " '002_dragon619468299972content',\n",
       " '002_dragon623245546434',\n",
       " '002_dragon623495405341content',\n",
       " '002_dragon625493329806content',\n",
       " '002_dragon634337155732content',\n",
       " '002_dragon636962270343content',\n",
       " '002_dragon643501113307',\n",
       " '002_dragon645239832728',\n",
       " '002_dragon645469919759content',\n",
       " '002_dragon647819242747content',\n",
       " '002_dragon648837860654content',\n",
       " '002_dragon660060898871content',\n",
       " '002_dragon664173122785content',\n",
       " '002_dragon669679313152content',\n",
       " '002_dragon671339860625content',\n",
       " '002_dragon671413180375',\n",
       " '002_dragon677407173143_',\n",
       " '002_dragon682176656828',\n",
       " '002_dragon682242077477',\n",
       " '002_dragon683701003467',\n",
       " '002_dragon683848968845',\n",
       " '002_dragon684485696525content',\n",
       " '002_dragon700393232030content',\n",
       " '002_dragon702086349026',\n",
       " '002_dragon706880655832content',\n",
       " '002_dragon710680206378',\n",
       " '002_dragon714483479317content',\n",
       " '002_dragon715506809858content',\n",
       " '002_dragon716684339575_',\n",
       " '002_dragon721447944431content',\n",
       " '002_dragon721496209399content',\n",
       " '002_dragon735922421923content',\n",
       " '002_dragon744366455165',\n",
       " '002_dragon745440808393content',\n",
       " '002_dragon745846869871content',\n",
       " '002_dragon749046174059',\n",
       " '002_dragon749135313276content',\n",
       " '002_dragon749616001928content',\n",
       " '002_dragon749775980445',\n",
       " '002_dragon752042517009content',\n",
       " '002_dragon752940174982content',\n",
       " '002_dragon756883035274content',\n",
       " '002_dragon758472607762',\n",
       " '002_dragon760169235045content',\n",
       " '002_dragon762646400558content',\n",
       " '002_dragon763409779758',\n",
       " '002_dragon773027103006',\n",
       " '002_dragon777504927530',\n",
       " '002_dragon779053823085content',\n",
       " '002_dragon779723947235content',\n",
       " '002_dragon785824725207',\n",
       " '002_dragon785883807422content',\n",
       " '002_dragon787036265046',\n",
       " '002_dragon788617422663',\n",
       " '002_dragon789549662168content',\n",
       " '002_dragon790560539053',\n",
       " '002_dragon790568223600',\n",
       " '002_dragon796954387895content',\n",
       " '002_dragon799105077372',\n",
       " '002_dragon803951708982content',\n",
       " '002_dragon805058253897content',\n",
       " '002_dragon806793363072',\n",
       " '002_dragon809654126877_',\n",
       " '002_dragon809864011866content',\n",
       " '002_dragon813633483461content',\n",
       " '002_dragon813978104655',\n",
       " '002_dragon820046601046content',\n",
       " '002_dragon821031089314content',\n",
       " '002_dragon833788956448_',\n",
       " '002_dragon835344230368content',\n",
       " '002_dragon835873675296content',\n",
       " '002_dragon836071345290',\n",
       " '002_dragon837387913413content',\n",
       " '002_dragon838552296986',\n",
       " '002_dragon844804994340content',\n",
       " '002_dragon852494520224',\n",
       " '002_dragon853396716332content',\n",
       " '002_dragon859035731542',\n",
       " '002_dragon866142856789',\n",
       " '002_dragon871663965498',\n",
       " '002_dragon872235195865content',\n",
       " '002_dragon875584409480content',\n",
       " '002_dragon882261761834',\n",
       " '002_dragon882895304044content',\n",
       " '002_dragon887388321534content',\n",
       " '002_dragon890168734255',\n",
       " '002_dragon890932882408content',\n",
       " '002_dragon898049280100content',\n",
       " '002_dragon908062144026content',\n",
       " '002_dragon912634163458content',\n",
       " '002_dragon917066359101',\n",
       " '002_dragon926841011669content',\n",
       " '002_dragon943687789736',\n",
       " '002_dragon953322195972content',\n",
       " '002_dragon955500430856content',\n",
       " '002_dragon956476021852content',\n",
       " '002_dragon959715935339content',\n",
       " '002_dragon966708873484content',\n",
       " '002_dragon966803059116content',\n",
       " '002_dragon975760983408content',\n",
       " '002_dragon975935048487content',\n",
       " '002_dragon980145547667content',\n",
       " '002_dragon981554492198content',\n",
       " '002_dragon984547041819',\n",
       " '002_dragon986057447477content',\n",
       " '002_dragon993740048225content',\n",
       " '002_dragon998760730906',\n",
       " '002_dragon998895130427content',\n",
       " '002a01c2724f',\n",
       " '002br',\n",
       " '002d01c26659',\n",
       " '002d01c66d57',\n",
       " '002d16e0',\n",
       " '002d16e0content',\n",
       " '002data',\n",
       " '002e62',\n",
       " '002f40f4',\n",
       " '002hn',\n",
       " '002letg',\n",
       " '002mk',\n",
       " '002s5',\n",
       " '002time',\n",
       " '003',\n",
       " '0030',\n",
       " '003001bee908',\n",
       " '00301320383e01e0383fffc0148014005b13f8ea33c00030c7fca4ea31fcea37ff383e0fc0383807e0ea3003000013f0a214f8a21238127c12fea200fc13f0a2387007e0003013c0383c1f80380fff00ea03f815207d9f1c',\n",
       " '0031',\n",
       " '00316',\n",
       " '0031630926532',\n",
       " '0031847131601',\n",
       " '0032',\n",
       " '003201c67c38',\n",
       " '0033',\n",
       " '003301beebdc',\n",
       " '003366',\n",
       " '0034',\n",
       " '0034pulse_default',\n",
       " '0034tcnt',\n",
       " '0035',\n",
       " '003501beebdf',\n",
       " '00353241',\n",
       " '0036',\n",
       " '0037',\n",
       " '0038',\n",
       " '0039',\n",
       " '003901beebdf',\n",
       " '003901c67c7a',\n",
       " '003_dragon056507828553_',\n",
       " '003_dragon346143145919_',\n",
       " '003_dragon402596564128_',\n",
       " '003_dragon838556541118_',\n",
       " '003_dragon899887122059_',\n",
       " '003br',\n",
       " '003c',\n",
       " '003c01c0fb80',\n",
       " '003f',\n",
       " '003fax',\n",
       " '003nl',\n",
       " '003pt',\n",
       " '004',\n",
       " '0040',\n",
       " '0040095e21234',\n",
       " '004093',\n",
       " '0040b0b1',\n",
       " '0040b0b10069f628',\n",
       " '0040b530',\n",
       " '0041',\n",
       " '004101c67c3c',\n",
       " '0042',\n",
       " '004201beebf9',\n",
       " '0043',\n",
       " '0043c77a',\n",
       " '0043fec0',\n",
       " '0044',\n",
       " '004499',\n",
       " '0044eb9c',\n",
       " '0044f6dc',\n",
       " '0045',\n",
       " '0045subroutine_servo_a5_init',\n",
       " '0046',\n",
       " '00465',\n",
       " '00466',\n",
       " '00467',\n",
       " '00468078',\n",
       " '0046937f',\n",
       " '00469d74',\n",
       " '00469d76',\n",
       " '0047',\n",
       " '0048',\n",
       " '0049',\n",
       " '0049servo_a5_pulse',\n",
       " '004all',\n",
       " '004c',\n",
       " '004nl',\n",
       " '005',\n",
       " '0050',\n",
       " '005004',\n",
       " '0050servo_a5_int',\n",
       " '005135',\n",
       " '0052',\n",
       " '0052servo_bit',\n",
       " '0053',\n",
       " '005301beedb7',\n",
       " '0054',\n",
       " '0055',\n",
       " '0056',\n",
       " '0057',\n",
       " '0058',\n",
       " '0059',\n",
       " '0059variable_servo_a5_pulse',\n",
       " '005a',\n",
       " '005amicrosoft',\n",
       " '005aupdate',\n",
       " '005c',\n",
       " '005d01bf6f13',\n",
       " '005hn',\n",
       " '005la',\n",
       " '005mk',\n",
       " '006',\n",
       " '0060',\n",
       " '0063',\n",
       " '00632d93',\n",
       " '0063825485257156_',\n",
       " '0063825485257156_content',\n",
       " '0063825785257156_',\n",
       " '0063825785257156_content',\n",
       " '00638260',\n",
       " '0063servo_enable',\n",
       " '0064',\n",
       " '0064setup_gap',\n",
       " '0065',\n",
       " '0066',\n",
       " '00664e75',\n",
       " '00667',\n",
       " '00667280',\n",
       " '0066993785257156_',\n",
       " '0066993785257156_content',\n",
       " '0066993a85257156_',\n",
       " '0066993a85257156_content',\n",
       " '00669945',\n",
       " '006765d8',\n",
       " '0067tctl1',\n",
       " '0068',\n",
       " '00681b6c',\n",
       " '0068a474',\n",
       " '0068a574',\n",
       " '0068bdbc',\n",
       " '0068da84',\n",
       " '0068uf',\n",
       " '0068uff',\n",
       " '0069',\n",
       " '00690340',\n",
       " '0069d154',\n",
       " '0069f5b8',\n",
       " '0069f5e0',\n",
       " '0069f5e0ecx',\n",
       " '0069f628',\n",
       " '0069fa36',\n",
       " '0069fcf8',\n",
       " '006a',\n",
       " '006a0604',\n",
       " '006b57d8',\n",
       " '006bb7f8',\n",
       " '006c',\n",
       " '006c2ce4',\n",
       " '006c67cc',\n",
       " '006e',\n",
       " '006hn',\n",
       " '006la',\n",
       " '006mk',\n",
       " '006nl',\n",
       " '006ov',\n",
       " '006performing',\n",
       " '006s1',\n",
       " '006s1_bias_avg',\n",
       " '007',\n",
       " '0070',\n",
       " '007083ac',\n",
       " '0071',\n",
       " '00717',\n",
       " '0072',\n",
       " '0072for',\n",
       " '0073',\n",
       " '00731864',\n",
       " '00734d74',\n",
       " '0074',\n",
       " '0075',\n",
       " '0076',\n",
       " '0076194298',\n",
       " '00762',\n",
       " '0077',\n",
       " '0077author',\n",
       " '0078',\n",
       " '0078email',\n",
       " '0078title',\n",
       " '0079',\n",
       " '00794d20',\n",
       " '00795ce0',\n",
       " '00798ab0',\n",
       " '007a4e40',\n",
       " '007a5580',\n",
       " '007b0100',\n",
       " '007b5860',\n",
       " '007br',\n",
       " '007cb350',\n",
       " '007fb512f839780780780060141800401408a300c0140c00801404a400001400b3a3497e3801fffe1e227ea123',\n",
       " '007fb61280a2397e03f80f00781407007014030060140100e015c0a200c01400a400001500b3a248b512f0a222227ea127',\n",
       " '007fb8fca39039c00ff801d87e00ec003f007c82007882a200708200f01780a3481603a5c792c7fcb3aa017fb6fca331307daf38',\n",
       " '007fd',\n",
       " '007parkerbros',\n",
       " '007you',\n",
       " '008',\n",
       " '0080',\n",
       " '00800',\n",
       " '008000',\n",
       " '0081',\n",
       " '0082',\n",
       " '0082toc3',\n",
       " '0083',\n",
       " '0083903358',\n",
       " '0083903358caveats',\n",
       " '0084',\n",
       " '008482',\n",
       " '0085',\n",
       " '0085weekly',\n",
       " '0086',\n",
       " '0087',\n",
       " '008723514',\n",
       " '0087411652337',\n",
       " '0088',\n",
       " '0088a100',\n",
       " '0088cforc',\n",
       " '0088office',\n",
       " '0089',\n",
       " '0089535',\n",
       " '0089tmsk1',\n",
       " '008br',\n",
       " '008cddec',\n",
       " '008ov',\n",
       " '008scan1',\n",
       " '008scan1testa',\n",
       " '009',\n",
       " '0090',\n",
       " '00901a',\n",
       " '0091',\n",
       " '0092',\n",
       " '0093',\n",
       " '0093according',\n",
       " '0093bac',\n",
       " '0093calls',\n",
       " '0093contact',\n",
       " '0093no',\n",
       " '0093subroutine_initialize_module',\n",
       " '0095',\n",
       " '0095setup_pulse',\n",
       " '0096',\n",
       " '0097',\n",
       " '0097612',\n",
       " '0097616095',\n",
       " '0097616095a',\n",
       " '0098',\n",
       " '009801c29c90',\n",
       " '0098d3',\n",
       " '0099',\n",
       " '009901c29c95',\n",
       " '0099ff',\n",
       " '009a01c29c9a',\n",
       " '009baba3',\n",
       " '009be502',\n",
       " '009br',\n",
       " '009c01bee96b',\n",
       " '009c0380',\n",
       " '009f00b0',\n",
       " '009mk',\n",
       " '00a301bee7d1',\n",
       " '00aa00342820',\n",
       " '00aa01c59196',\n",
       " '00am',\n",
       " '00analog',\n",
       " '00assistant',\n",
       " '00b13250',\n",
       " '00b14878',\n",
       " '00c',\n",
       " '00cf01bee7d2',\n",
       " '00customers',\n",
       " '00dc',\n",
       " '00e03u',\n",
       " '00e2',\n",
       " '00e4',\n",
       " '00est',\n",
       " '00euro',\n",
       " '00ff',\n",
       " '00for',\n",
       " '00from',\n",
       " '00golden',\n",
       " '00i',\n",
       " '00in',\n",
       " '00jan',\n",
       " '00ms',\n",
       " '00ms0',\n",
       " '00msgraphic',\n",
       " '00multiple',\n",
       " '00noon',\n",
       " '00numbers',\n",
       " '00p',\n",
       " '00pm',\n",
       " '00pma',\n",
       " '00pmemu',\n",
       " '00pmregistration',\n",
       " '00pmtake',\n",
       " '00pmthe',\n",
       " '00pmweir',\n",
       " '00pnear',\n",
       " '00processor',\n",
       " '00r',\n",
       " '00readme',\n",
       " '00secondary',\n",
       " '00session',\n",
       " '00shipping',\n",
       " '00subject',\n",
       " '00subroutine_initialize_module',\n",
       " '00the',\n",
       " '00tim',\n",
       " '00time',\n",
       " '00total',\n",
       " '00u',\n",
       " '00ui',\n",
       " '00usd',\n",
       " '00use',\n",
       " '00v',\n",
       " '00variable_tcount',\n",
       " '00vga',\n",
       " '00what',\n",
       " '00which',\n",
       " '00x0c',\n",
       " '00x0f',\n",
       " '00you',\n",
       " '00z',\n",
       " '00以後',\n",
       " '01',\n",
       " '010',\n",
       " '0100',\n",
       " '01000000',\n",
       " '01000000spdsetc',\n",
       " '0100007f',\n",
       " '01002',\n",
       " '01002413',\n",
       " '0100a8c0',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# equivalently: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23230x154169 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2307898 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7744x154169 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 734621 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 5: Building and evaluating a model\n",
    "\n",
    "We will use [multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.9 ms, sys: 9.63 ms, total: 44.5 ms\n",
      "Wall time: 43.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98514979338842978"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2885,    8],\n",
       "       [ 107, 4744]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9642    0.9972    0.9805      2893\n",
      "          1     0.9983    0.9779    0.9880      4851\n",
      "\n",
      "avg / total     0.9856    0.9851    0.9852      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred_class, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   6.49899204e-21,   1.00000000e+00, ...,\n",
       "         1.37521821e-22,   1.00000000e+00,   1.00000000e+00])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99703632827922983"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 7: Examining a model for further insight\n",
    "\n",
    "We will examine the our **trained Naive Bayes model** to calculate the approximate **\"spamminess\" of each token**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154169"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '000000', '0000000', '00000000', '000000000', '00000000000000', '000000000000000000000000000000049999999999999e9', '0000000000000000000000000000000500000000000000e9', '0000000000000016666l', '0000000000000017d', '00000000000000e', '0000000000status', '0000000001d0', '0000000001l0', '0000000010000000004l0', '0000000016', '000000001d0', '00000000message', '00000000x', '00000001', '00000001irdecode', '00000004', '00000010', '00000010pwm', '00000011', '0000001196', '00000049', '0000005', '000000eb', '000001', '00000100', '00000100shaftencoder', '000001bdaaa0', '000001bdc5a5', '000001bdcaf3', '000001bdd411', '000001bdd98c', '000001bdda70', '000001bde0a0', '000001bed6b7', '000001c64310', '000001c64562', '000001c64585', '000001c64615', '000001c6465f', '000001c6468e', '000001c676b8', '0000020']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['３ｄバーチャルｓｅｘメーカー', '４名紹介http', '４月度新規メンバー様応援企画パーティー開催予定', '４月２３日', '５月までのようなので興味のある方はお早めに', '５月中週末３人か４人ぐらいで', '５００円分のポイントが完全無料で自動追加されます', '６名のみとなります', 'ａ型', 'ａ美様現在未亡人でいらっしゃいます', 'ｂ９６', 'ｆカップ', 'ｇａｌ誌多数掲載', 'ｇｏｏｄ', 'ｇｒａｎｄｅｅ', 'ｇｒａｎｄｅｅの理念やシステムのご紹介', 'ｇｗこそ出会いのチャンスhttp', 'ｇｗです', 'ｇｗはこういう女の子と過ごしたいっす', 'ｇｗ特典あり', 'ｈなこと大好きな人ばかり', 'ｈな女の子が多いので', 'ｈな欲望や願望を胸に秘め', 'ｈにそんなに興味なかったのと少し怖いのもあるため', 'ｈのお相手しただけで', 'ｈゲームメーカーの決定版', 'ｈ度', 'ｈ目的の出会いも簡単です', 'ｈ８６', 'ｋ村', 'ｍ子様セーリングクルーザーをお持ちで', 'ｍ字開脚オナニーを机の下から盗撮', 'ｍａｉｌでのサポートは２４時間対応です', 'ｎ藤', 'ｏｌ', 'ｐｃ', 'ｐｃから簡単プロフィール作成', 'ｓクラス専門店', 'ｓ子様秘密が条件で', 'ｓｅｘを求めている', 'ｓｅｘを求めているのです', 'ｓｍ', 'ｔ165', 'ｔバックは', 'ｔバックはいていたらおならが左右に分散するのでなんか変な感じですけどね', 'ｔバックを購入しました', 'ｔ島', 'ｔ谷', 'ｗ６２', 'ｙ里様お互いがくつろげるような']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.09000000e+03,   4.46000000e+02,   3.71000000e+02, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  3.39200000e+03,   5.36400000e+03,   2.00000000e+00, ...,\n",
       "          2.00000000e+00,   2.00000000e+00,   2.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 154169)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2090.,   446.,   371., ...,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.39200000e+03,   5.36400000e+03,   2.00000000e+00, ...,\n",
       "         2.00000000e+00,   2.00000000e+00,   2.00000000e+00])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>2090.0</td>\n",
       "      <td>3392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>446.0</td>\n",
       "      <td>5364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>371.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000</th>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ham    spam\n",
       "token                  \n",
       "00       2090.0  3392.0\n",
       "000       446.0  5364.0\n",
       "0000      371.0     2.0\n",
       "000000     19.0    44.0\n",
       "0000000     1.0     0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')\n",
    "tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precious</th>\n",
       "      <td>10.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mehmel</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statepark</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cutdown</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloodsupply</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ham  spam\n",
       "token                  \n",
       "precious     10.0  76.0\n",
       "mehmel        1.0   0.0\n",
       "statepark     2.0   0.0\n",
       "cutdown       3.0   0.0\n",
       "bloodsupply   1.0   0.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8801.,  14429.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Before we can calculate the \"spamminess\" of each token, we need to avoid **dividing by zero** and account for the **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>squared</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hopeless</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>削除して下さい</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shortcuts</th>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resolutionof</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ham  spam\n",
       "token                   \n",
       "squared       11.0   1.0\n",
       "hopeless       3.0   3.0\n",
       "削除して下さい        1.0   5.0\n",
       "shortcuts     20.0   1.0\n",
       "resolutionof   4.0   1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setsdate</th>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memorial</th>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0800received</th>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goofy</th>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senden</th>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ham      spam\n",
       "token                           \n",
       "setsdate      0.000227  0.000069\n",
       "memorial      0.001704  0.000069\n",
       "0800received  0.001136  0.000069\n",
       "goofy         0.001250  0.000069\n",
       "senden        0.000454  0.000347"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "tokens.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>factorin</th>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.304976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9700</th>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.087136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detain</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>6.709474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>otheranalogue</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.203317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overloaded</th>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.087136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ham      spam  spam_ratio\n",
       "token                                        \n",
       "factorin       0.000227  0.000069    0.304976\n",
       "9700           0.000795  0.000069    0.087136\n",
       "detain         0.000114  0.000762    6.709474\n",
       "otheranalogue  0.000341  0.000069    0.203317\n",
       "overloaded     0.000795  0.000069    0.087136"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product_table</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.601012</td>\n",
       "      <td>5289.505302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px</th>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.681336</td>\n",
       "      <td>1998.813293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13px</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.189133</td>\n",
       "      <td>1664.559498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15px</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.188994</td>\n",
       "      <td>1663.339594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.150599</td>\n",
       "      <td>1325.426086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professionaladobe</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.150599</td>\n",
       "      <td>1325.426086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hereopt</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.126620</td>\n",
       "      <td>1114.382632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.115185</td>\n",
       "      <td>1013.740523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_description</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.112967</td>\n",
       "      <td>994.222053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95more</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.112967</td>\n",
       "      <td>994.222053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewsretail</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.112967</td>\n",
       "      <td>994.222053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00you</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.112967</td>\n",
       "      <td>994.222053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hoodia</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.104304</td>\n",
       "      <td>917.978030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>無料</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.103472</td>\n",
       "      <td>910.658604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs2</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.099938</td>\n",
       "      <td>879.551043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cantex</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.099868</td>\n",
       "      <td>878.941091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weightzipping</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.083235</td>\n",
       "      <td>732.552568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff0000</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.081572</td>\n",
       "      <td>717.913715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestsellers</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.076374</td>\n",
       "      <td>672.167302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proadobe</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>663.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5adobe</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>663.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp_cont</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>663.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_image</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>663.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collectionadobe</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>663.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compacted_price</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>663.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greylink</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>663.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00c</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>663.018019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bz</th>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.124264</td>\n",
       "      <td>546.822129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rolex</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.061335</td>\n",
       "      <td>539.807679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discreet</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.058563</td>\n",
       "      <td>515.409592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fred</th>\n",
       "      <td>0.058857</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voltage</th>\n",
       "      <td>0.059766</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <td>0.059880</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sunbird</th>\n",
       "      <td>0.059993</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensors</th>\n",
       "      <td>0.060334</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analog</th>\n",
       "      <td>0.060902</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>output</th>\n",
       "      <td>0.123054</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timedx</th>\n",
       "      <td>0.062493</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vu</th>\n",
       "      <td>0.062720</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>servo</th>\n",
       "      <td>0.062834</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmp</th>\n",
       "      <td>0.067947</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonar</th>\n",
       "      <td>0.069765</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ir</th>\n",
       "      <td>0.075332</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pgp</th>\n",
       "      <td>0.077718</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensor</th>\n",
       "      <td>0.082150</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thu</th>\n",
       "      <td>0.082604</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>motors</th>\n",
       "      <td>0.091581</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linux</th>\n",
       "      <td>0.097375</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libimlib</th>\n",
       "      <td>0.098284</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sep</th>\n",
       "      <td>0.101693</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starship</th>\n",
       "      <td>0.103284</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>0.111578</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil</th>\n",
       "      <td>0.335871</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon</th>\n",
       "      <td>0.119077</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>port</th>\n",
       "      <td>0.138393</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy</th>\n",
       "      <td>0.156687</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>0.163731</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>0.171003</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hb</th>\n",
       "      <td>0.198046</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert</th>\n",
       "      <td>0.209408</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154169 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ham      spam   spam_ratio\n",
       "token                                                 \n",
       "product_table          0.000114  0.601012  5289.505302\n",
       "0px                    0.000341  0.681336  1998.813293\n",
       "13px                   0.000114  0.189133  1664.559498\n",
       "15px                   0.000114  0.188994  1663.339594\n",
       "proms                  0.000114  0.150599  1325.426086\n",
       "professionaladobe      0.000114  0.150599  1325.426086\n",
       "hereopt                0.000114  0.126620  1114.382632\n",
       "fff                    0.000114  0.115185  1013.740523\n",
       "compacted_description  0.000114  0.112967   994.222053\n",
       "95more                 0.000114  0.112967   994.222053\n",
       "reviewsretail          0.000114  0.112967   994.222053\n",
       "00you                  0.000114  0.112967   994.222053\n",
       "hoodia                 0.000114  0.104304   917.978030\n",
       "無料                     0.000114  0.103472   910.658604\n",
       "cs2                    0.000114  0.099938   879.551043\n",
       "cantex                 0.000114  0.099868   878.941091\n",
       "weightzipping          0.000114  0.083235   732.552568\n",
       "ff0000                 0.000114  0.081572   717.913715\n",
       "bestsellers            0.000114  0.076374   672.167302\n",
       "proadobe               0.000114  0.075334   663.018019\n",
       "5adobe                 0.000114  0.075334   663.018019\n",
       "sp_cont                0.000114  0.075334   663.018019\n",
       "compacted_image        0.000114  0.075334   663.018019\n",
       "collectionadobe        0.000114  0.075334   663.018019\n",
       "compacted_price        0.000114  0.075334   663.018019\n",
       "greylink               0.000114  0.075334   663.018019\n",
       "00c                    0.000114  0.075334   663.018019\n",
       "bz                     0.000227  0.124264   546.822129\n",
       "rolex                  0.000114  0.061335   539.807679\n",
       "discreet               0.000114  0.058563   515.409592\n",
       "...                         ...       ...          ...\n",
       "fred                   0.058857  0.000069     0.001178\n",
       "voltage                0.059766  0.000069     0.001160\n",
       "object                 0.059880  0.000069     0.001157\n",
       "sunbird                0.059993  0.000069     0.001155\n",
       "sensors                0.060334  0.000069     0.001149\n",
       "analog                 0.060902  0.000069     0.001138\n",
       "output                 0.123054  0.000139     0.001126\n",
       "timedx                 0.062493  0.000069     0.001109\n",
       "vu                     0.062720  0.000069     0.001105\n",
       "servo                  0.062834  0.000069     0.001103\n",
       "bmp                    0.067947  0.000069     0.001020\n",
       "sonar                  0.069765  0.000069     0.000993\n",
       "ir                     0.075332  0.000069     0.000920\n",
       "pgp                    0.077718  0.000069     0.000892\n",
       "sensor                 0.082150  0.000069     0.000844\n",
       "thu                    0.082604  0.000069     0.000839\n",
       "motors                 0.091581  0.000069     0.000757\n",
       "linux                  0.097375  0.000069     0.000712\n",
       "libimlib               0.098284  0.000069     0.000705\n",
       "sep                    0.101693  0.000069     0.000682\n",
       "starship               0.103284  0.000069     0.000671\n",
       "robot                  0.111578  0.000069     0.000621\n",
       "nil                    0.335871  0.000208     0.000619\n",
       "ribbon                 0.119077  0.000069     0.000582\n",
       "port                   0.138393  0.000069     0.000501\n",
       "handy                  0.156687  0.000069     0.000442\n",
       "nodes                  0.163731  0.000069     0.000423\n",
       "node                   0.171003  0.000069     0.000405\n",
       "hb                     0.198046  0.000069     0.000350\n",
       "cert                   0.209408  0.000069     0.000331\n",
       "\n",
       "[154169 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.742940193913022"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the spam_ratio for a given token\n",
    "# Note that the specified token, adobe, can change due to the nature of randomness\n",
    "tokens.loc['adobe', 'spam_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 9: Tuning the vectorizer (Challenge)\n",
    "\n",
    "Thus far, we have been using the default parameters of [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show default parameters for CountVectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "However, the vectorizer is worth tuning, just like a model is worth tuning! Here are a few parameters that you might want to tune:\n",
    "\n",
    "- **stop_words:** string {'english'}, list, or None (default)\n",
    "    - If 'english', a built-in stop word list for English is used.\n",
    "    - If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens.\n",
    "    - If None, no stop words will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# remove English stop words\n",
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **ngram_range:** tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different n-grams to be extracted.\n",
    "    - All values of n such that min_n <= n <= max_n will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **max_df:** float in range [0.0, 1.0] or int, default=1.0\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words).\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# ignore terms that appear in more than 50% of the documents\n",
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "- **min_df:** float in range [0.0, 1.0] or int, default=1\n",
    "    - When building the vocabulary, ignore terms that have a document frequency strictly lower than the given threshold. (This value is also called \"cut-off\" in the literature.)\n",
    "    - If float, the parameter represents a proportion of documents.\n",
    "    - If integer, the parameter represents an absolute count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# only keep terms that appear in at least 2 documents\n",
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "**Guidelines for tuning CountVectorizer:**\n",
    "\n",
    "- Use your knowledge of the **problem** and the **text**, and your understanding of the **tuning parameters**, to help you decide what parameters to tune and how to tune them.\n",
    "\n",
    "Tasks:\n",
    "1. **Experiment**, and let the data tell you the best approach!\n",
    "    * Try using GridSearch on the CountVectorizer!\n",
    "2. Try to reduce or increase the features and get a better score on the previous model. \n",
    "    * Score above a 99.5%? Tell us! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23230, 8561201)\n",
      "(7744, 8561201)\n",
      "(23230,)\n",
      "(7744,)\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 7), max_df=0.95)\n",
    "X_trimmed = vect.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trimmed, y)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8561201"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "print(classification_report(y_test, nb.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ham_token_count = nb.feature_count_[0, :]\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nil nil</th>\n",
       "      <td>3325.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil nil</th>\n",
       "      <td>2846.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil nil nil</th>\n",
       "      <td>2370.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil nil nil nil</th>\n",
       "      <td>1926.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cert</th>\n",
       "      <td>1813.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hb</th>\n",
       "      <td>1645.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <td>1516.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil nil nil nil nil</th>\n",
       "      <td>1506.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <td>1438.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy</th>\n",
       "      <td>1403.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil</th>\n",
       "      <td>4040.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starship</th>\n",
       "      <td>1290.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>handy board</th>\n",
       "      <td>1265.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starship design</th>\n",
       "      <td>1259.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usd edu</th>\n",
       "      <td>1155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>port</th>\n",
       "      <td>1152.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nil nil nil nil nil nil nil</th>\n",
       "      <td>1086.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon</th>\n",
       "      <td>1051.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon campaign</th>\n",
       "      <td>1030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon campaign html</th>\n",
       "      <td>1018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign html mail</th>\n",
       "      <td>1018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign html</th>\n",
       "      <td>1018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ribbon campaign html mail</th>\n",
       "      <td>1018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ascii ribbon</th>\n",
       "      <td>1007.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ascii ribbon campaign</th>\n",
       "      <td>1007.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonathan ascii ribbon campaign html</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ascii ribbon campaign html mail</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonathan ascii ribbon</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonathan ascii</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jonathan ascii ribbon campaign</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xp proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium border</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xp proms office 2003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windows xp proms office 2003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>info microsoft</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windows xp proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border medium</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69 95 add cart</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price 69</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price 69 95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price 69 95 add</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windows xp proms office</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price 69 95 add cart</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69 95 add</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms office 2003</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms office</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proms</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>padding left 0px padding</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>2263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left 0px padding</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2263.0</td>\n",
       "      <td>2263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69 95</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2476.0</td>\n",
       "      <td>2476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0px</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10210.0</td>\n",
       "      <td>2552.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd 1px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>2821.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddd 1px solid</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2821.0</td>\n",
       "      <td>2821.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>padding left 0px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2827.0</td>\n",
       "      <td>2827.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>left 0px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>2830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15px</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2833.0</td>\n",
       "      <td>2833.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>add cart</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3385.0</td>\n",
       "      <td>3385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95 add</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3385.0</td>\n",
       "      <td>3385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95 add cart</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3385.0</td>\n",
       "      <td>3385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_table</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9008.0</td>\n",
       "      <td>9008.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8561201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ham     spam   spam_ratio\n",
       "token                                                            \n",
       "nil nil                              3325.0      1.0     0.000301\n",
       "nil nil nil                          2846.0      1.0     0.000351\n",
       "nil nil nil nil                      2370.0      1.0     0.000422\n",
       "nil nil nil nil nil                  1926.0      1.0     0.000519\n",
       "cert                                 1813.0      1.0     0.000552\n",
       "hb                                   1645.0      1.0     0.000608\n",
       "node                                 1516.0      1.0     0.000660\n",
       "nil nil nil nil nil nil              1506.0      1.0     0.000664\n",
       "nodes                                1438.0      1.0     0.000695\n",
       "handy                                1403.0      1.0     0.000713\n",
       "nil                                  4040.0      3.0     0.000743\n",
       "starship                             1290.0      1.0     0.000775\n",
       "handy board                          1265.0      1.0     0.000791\n",
       "starship design                      1259.0      1.0     0.000794\n",
       "usd edu                              1155.0      1.0     0.000866\n",
       "port                                 1152.0      1.0     0.000868\n",
       "nil nil nil nil nil nil nil          1086.0      1.0     0.000921\n",
       "ribbon                               1051.0      1.0     0.000951\n",
       "ribbon campaign                      1030.0      1.0     0.000971\n",
       "ribbon campaign html                 1018.0      1.0     0.000982\n",
       "campaign html mail                   1018.0      1.0     0.000982\n",
       "campaign html                        1018.0      1.0     0.000982\n",
       "ribbon campaign html mail            1018.0      1.0     0.000982\n",
       "ascii ribbon                         1007.0      1.0     0.000993\n",
       "ascii ribbon campaign                1007.0      1.0     0.000993\n",
       "jonathan ascii ribbon campaign html  1002.0      1.0     0.000998\n",
       "ascii ribbon campaign html mail      1002.0      1.0     0.000998\n",
       "jonathan ascii ribbon                1002.0      1.0     0.000998\n",
       "jonathan ascii                       1002.0      1.0     0.000998\n",
       "jonathan ascii ribbon campaign       1002.0      1.0     0.000998\n",
       "...                                     ...      ...          ...\n",
       "xp proms                                1.0   2257.0  2257.000000\n",
       "medium border                           1.0   2257.0  2257.000000\n",
       "xp proms office 2003                    1.0   2257.0  2257.000000\n",
       "windows xp proms office 2003            1.0   2257.0  2257.000000\n",
       "info microsoft                          1.0   2257.0  2257.000000\n",
       "windows xp proms                        1.0   2257.0  2257.000000\n",
       "border medium                           1.0   2257.0  2257.000000\n",
       "69 95 add cart                          1.0   2257.0  2257.000000\n",
       "price 69                                1.0   2257.0  2257.000000\n",
       "price 69 95                             1.0   2257.0  2257.000000\n",
       "price 69 95 add                         1.0   2257.0  2257.000000\n",
       "windows xp proms office                 1.0   2257.0  2257.000000\n",
       "price 69 95 add cart                    1.0   2257.0  2257.000000\n",
       "69 95 add                               1.0   2257.0  2257.000000\n",
       "proms office 2003                       1.0   2257.0  2257.000000\n",
       "proms office                            1.0   2257.0  2257.000000\n",
       "proms                                   1.0   2257.0  2257.000000\n",
       "padding left 0px padding                1.0   2263.0  2263.000000\n",
       "left 0px padding                        1.0   2263.0  2263.000000\n",
       "69 95                                   1.0   2476.0  2476.000000\n",
       "0px                                     4.0  10210.0  2552.500000\n",
       "ddd 1px                                 1.0   2821.0  2821.000000\n",
       "ddd 1px solid                           1.0   2821.0  2821.000000\n",
       "padding left 0px                        1.0   2827.0  2827.000000\n",
       "left 0px                                1.0   2830.0  2830.000000\n",
       "15px                                    1.0   2833.0  2833.000000\n",
       "add cart                                1.0   3385.0  3385.000000\n",
       "95 add                                  1.0   3385.0  3385.000000\n",
       "95 add cart                             1.0   3385.0  3385.000000\n",
       "product_table                           1.0   9008.0  9008.000000\n",
       "\n",
       "[8561201 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sort_values('spam_ratio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Part 10: Tuning the Laplacian Correction Factor (Challenge)\n",
    "\n",
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> class sklearn.naive_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n",
    "\n",
    "> Parameters:\t\n",
    "alpha : float, optional (default=1.0)\n",
    "Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
    "\n",
    "One of the parameters that we can tune in training a Multinomial Naive Bayes Classifier is the Laplacian Correction Factor.\n",
    "\n",
    "Tasks:\n",
    "1. Tweak the correction factor from 0-3 in increments of 0.1, 5, and 10, thus training multiple classifiers.\n",
    "2. Plot the precision-recall curves for these classifiers to compare and contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [MultinomialNB(alpha=i) for i in np.concatenate((np.arange(0, 3.1, 0.1), [5, 10]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hadrian/anaconda/lib/python3.6/site-packages/sklearn/naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n"
     ]
    }
   ],
   "source": [
    "for i in classifiers:\n",
    "    i.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1555e2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "for i in classifiers:\n",
    "    precision, recall, _ = precision_recall_curve(y_test.ravel(),\n",
    "        i.predict(X_test).ravel())\n",
    "    average_precision = average_precision_score(y_test, i.predict(X_test).ravel(),\n",
    "                                                         average=\"micro\")\n",
    "    plot(recall, precision,\n",
    "             label='micro-average Precision-recall curve (area = {0:0.2f})'\n",
    "                   ''.format(average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9117    0.9997    0.9536      2973\n",
      "          1     0.9998    0.9396    0.9688      4771\n",
      "\n",
      "avg / total     0.9659    0.9627    0.9630      7744\n",
      "\n",
      "0.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9933    0.9963    0.9948      2973\n",
      "          1     0.9977    0.9958    0.9967      4771\n",
      "\n",
      "avg / total     0.9960    0.9960    0.9960      7744\n",
      "\n",
      "0.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9930    0.9963    0.9946      2973\n",
      "          1     0.9977    0.9956    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "0.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "0.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "0.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "0.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "0.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "0.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "0.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9926    0.9966    0.9946      2973\n",
      "          1     0.9979    0.9954    0.9966      4771\n",
      "\n",
      "avg / total     0.9959    0.9959    0.9959      7744\n",
      "\n",
      "1.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9920    0.9966    0.9943      2973\n",
      "          1     0.9979    0.9950    0.9964      4771\n",
      "\n",
      "avg / total     0.9956    0.9956    0.9956      7744\n",
      "\n",
      "1.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9920    0.9966    0.9943      2973\n",
      "          1     0.9979    0.9950    0.9964      4771\n",
      "\n",
      "avg / total     0.9956    0.9956    0.9956      7744\n",
      "\n",
      "1.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9916    0.9966    0.9941      2973\n",
      "          1     0.9979    0.9948    0.9963      4771\n",
      "\n",
      "avg / total     0.9955    0.9955    0.9955      7744\n",
      "\n",
      "1.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9906    0.9963    0.9935      2973\n",
      "          1     0.9977    0.9941    0.9959      4771\n",
      "\n",
      "avg / total     0.9950    0.9950    0.9950      7744\n",
      "\n",
      "1.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9903    0.9966    0.9935      2973\n",
      "          1     0.9979    0.9939    0.9959      4771\n",
      "\n",
      "avg / total     0.9950    0.9950    0.9950      7744\n",
      "\n",
      "1.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9903    0.9966    0.9935      2973\n",
      "          1     0.9979    0.9939    0.9959      4771\n",
      "\n",
      "avg / total     0.9950    0.9950    0.9950      7744\n",
      "\n",
      "1.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9903    0.9966    0.9935      2973\n",
      "          1     0.9979    0.9939    0.9959      4771\n",
      "\n",
      "avg / total     0.9950    0.9950    0.9950      7744\n",
      "\n",
      "1.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9896    0.9966    0.9931      2973\n",
      "          1     0.9979    0.9935    0.9957      4771\n",
      "\n",
      "avg / total     0.9947    0.9947    0.9947      7744\n",
      "\n",
      "1.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9896    0.9966    0.9931      2973\n",
      "          1     0.9979    0.9935    0.9957      4771\n",
      "\n",
      "avg / total     0.9947    0.9947    0.9947      7744\n",
      "\n",
      "2.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9896    0.9966    0.9931      2973\n",
      "          1     0.9979    0.9935    0.9957      4771\n",
      "\n",
      "avg / total     0.9947    0.9947    0.9947      7744\n",
      "\n",
      "2.1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9896    0.9966    0.9931      2973\n",
      "          1     0.9979    0.9935    0.9957      4771\n",
      "\n",
      "avg / total     0.9947    0.9947    0.9947      7744\n",
      "\n",
      "2.2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9887    0.9966    0.9926      2973\n",
      "          1     0.9979    0.9929    0.9954      4771\n",
      "\n",
      "avg / total     0.9943    0.9943    0.9943      7744\n",
      "\n",
      "2.3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9887    0.9966    0.9926      2973\n",
      "          1     0.9979    0.9929    0.9954      4771\n",
      "\n",
      "avg / total     0.9943    0.9943    0.9943      7744\n",
      "\n",
      "2.4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9887    0.9966    0.9926      2973\n",
      "          1     0.9979    0.9929    0.9954      4771\n",
      "\n",
      "avg / total     0.9943    0.9943    0.9943      7744\n",
      "\n",
      "2.5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9887    0.9966    0.9926      2973\n",
      "          1     0.9979    0.9929    0.9954      4771\n",
      "\n",
      "avg / total     0.9943    0.9943    0.9943      7744\n",
      "\n",
      "2.6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9883    0.9966    0.9925      2973\n",
      "          1     0.9979    0.9927    0.9953      4771\n",
      "\n",
      "avg / total     0.9942    0.9942    0.9942      7744\n",
      "\n",
      "2.7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9880    0.9966    0.9923      2973\n",
      "          1     0.9979    0.9925    0.9952      4771\n",
      "\n",
      "avg / total     0.9941    0.9941    0.9941      7744\n",
      "\n",
      "2.8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9880    0.9966    0.9923      2973\n",
      "          1     0.9979    0.9925    0.9952      4771\n",
      "\n",
      "avg / total     0.9941    0.9941    0.9941      7744\n",
      "\n",
      "2.9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9880    0.9966    0.9923      2973\n",
      "          1     0.9979    0.9925    0.9952      4771\n",
      "\n",
      "avg / total     0.9941    0.9941    0.9941      7744\n",
      "\n",
      "3.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9880    0.9966    0.9923      2973\n",
      "          1     0.9979    0.9925    0.9952      4771\n",
      "\n",
      "avg / total     0.9941    0.9941    0.9941      7744\n",
      "\n",
      "5.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9870    0.9966    0.9918      2973\n",
      "          1     0.9979    0.9918    0.9948      4771\n",
      "\n",
      "avg / total     0.9937    0.9937    0.9937      7744\n",
      "\n",
      "10.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0     0.9854    0.9963    0.9908      2973\n",
      "          1     0.9977    0.9908    0.9942      4771\n",
      "\n",
      "avg / total     0.9930    0.9929    0.9929      7744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in classifiers:\n",
    "    print(i.get_params()['alpha'])\n",
    "    print(classification_report(y_test, i.predict(X_test),digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
